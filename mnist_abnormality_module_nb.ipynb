{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Most of the codes below are copied from '02.mnist_abnormality_module.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import experiments_aux as exp\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from noise_util import add_distortion_noise, add_distortion_blur\n",
    "from noise_util import rotate90_if_not_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer for merging 3 layers into.\n",
    "class Merge3Ways(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(Merge3Ways, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        # Destructuring shapes\n",
    "        shape_x, shape_h2, shape_logits, shape_rec =\\\n",
    "                list(map(lambda shape: int(shape[1]), input_shape))\n",
    "\n",
    "        self.weight1 = self.add_weight(name='h2_to_merge',\n",
    "                                       shape=(shape_h2, self.output_dim))\n",
    "        self.weight2 = self.add_weight(name='logits_to_merge',\n",
    "                                       shape=(shape_logits, self.output_dim))\n",
    "        self.weight3 = self.add_weight(name='rec_to_merge',\n",
    "                                       shape=(shape_rec, self.output_dim))\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.output_dim,))\n",
    "        super(Merge3Ways, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        x, h2, logits_out, reconstruction = inputs\n",
    "        a1 = K.dot(h2, self.weight1)\n",
    "        a2 = K.dot(logits_out, self.weight2)\n",
    "        a3 = K.dot(K.square(reconstruction-x), self.weight3)\n",
    "        return (a1 + a2 + a3) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns trained auxiliary base model\n",
    "def train_aux_base_model():\n",
    "    # TRAIN MODEL\n",
    "    training_epochs = 10\n",
    "    image_size = 28\n",
    "    input_dim = image_size * image_size\n",
    "    n_labels = 10\n",
    "    bottleneck_dim = 128\n",
    "    batch_size = 128\n",
    "\n",
    "    # Base model\n",
    "    inputs = Input(shape=(input_dim, ), name='image_input')\n",
    "    h1 = Dense(256, activation='relu', name='h1')(inputs)\n",
    "    h2 = Dense(256, activation='relu', name='h2')(h1)\n",
    "\n",
    "    # Softmax logits output\n",
    "    h3 = Dense(256, activation='relu', name='h3')(h2)\n",
    "    logits_out = Dense(n_labels, activation='softmax', name='logits_out')(h3)\n",
    "\n",
    "    # Reconstruction image output\n",
    "    bottleneck = Dense(bottleneck_dim,\n",
    "                       activation='relu',\n",
    "                       name='bottleneck')(h2)\n",
    "    decode1 = Dense(256, activation='relu', name='decode1')(bottleneck)\n",
    "    decode2 = Dense(256, activation='relu', name='decode2')(decode1)\n",
    "    reconstruction = Dense(input_dim, name='rec_output')(decode2)\n",
    "\n",
    "    # Instantiate base model\n",
    "    base_model = Model(inputs, [h2, logits_out, reconstruction], name='base')\n",
    "\n",
    "    base_model.compile(optimizer='adam',\n",
    "                       loss={'logits_out': 'sparse_categorical_crossentropy',\n",
    "                             'rec_output': 'mean_squared_error'},\n",
    "                       loss_weights={'logits_out': 0.9,\n",
    "                                     'rec_output': 0.1})\n",
    "\n",
    "    base_model.fit(mnist_train_x,\n",
    "                   {'logits_out': mnist_train_y,\n",
    "                    'rec_output': mnist_train_x},\n",
    "                   epochs=training_epochs, batch_size=batch_size)\n",
    "\n",
    "    # test_loss, test_acc\n",
    "    test_result = base_model.evaluate(x=mnist_test_x,\n",
    "                                      y={'logits_out': mnist_test_y,\n",
    "                                         'rec_output': mnist_test_x})\n",
    "\n",
    "    print(\"metric names:\", base_model.metrics_names)\n",
    "    print(test_result)\n",
    "\n",
    "    # SAVE MODEL\n",
    "    keras.models.save_model(base_model, \"./mnist_aux_base.hdf5\")\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to base model, merge all output layers to external module\n",
    "def train_abnormal_model(base_model):\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 128\n",
    "\n",
    "    image_inputs = base_model.inputs[0]\n",
    "\n",
    "    # Deconstruct outputs from previous base model\n",
    "    h2, logits_out, reconstruction = base_model.outputs\n",
    "\n",
    "    merged = Merge3Ways(512)([image_inputs, h2, logits_out, reconstruction])\n",
    "\n",
    "    risk_1 = Dense(128, activation='relu', name='risk_1')(merged)\n",
    "    risk_out = Dense(1, name='risk_out', activation='sigmoid')(risk_1)\n",
    "\n",
    "    # Instantiate abnormality module\n",
    "    aux_model = Model(image_inputs, [logits_out, risk_out])\n",
    "\n",
    "    # Freeze base model layers to prevent optimization\n",
    "    for l in base_model.layers:\n",
    "        l.trainable = False\n",
    "\n",
    "    # Setup datasets for training abnormality module\n",
    "    batches = []\n",
    "\n",
    "    # We'll take train:test datasets at the ratio of 2:1 in single batch,\n",
    "    # then will tweak half of them.\n",
    "    def mnist_fetcher(mnist_x, chunksize, mnist_y=None):\n",
    "        num_chunks = mnist_x.shape[0] // chunksize\n",
    "        for i in range(num_chunks):\n",
    "            if mnist_y is not None:\n",
    "                yield [mnist_x[i * chunksize: (i + 1) * chunksize],\n",
    "                       mnist_y[i * chunksize: (i + 1) * chunksize]]\n",
    "            else:\n",
    "                yield mnist_x[i * chunksize: (i + 1) * chunksize]\n",
    "\n",
    "    chunksize_train = int(batch_size*(4/6))\n",
    "    chunksize_test = int(batch_size*(2/6))\n",
    "\n",
    "    tcu = chunksize_train // 4\n",
    "    for (train_x, train_y), test in\\\n",
    "        zip(mnist_fetcher(mnist_train_x, chunksize_train, mnist_train_y),\n",
    "            mnist_fetcher(mnist_test_x, chunksize_test)):\n",
    "\n",
    "        # In-distribution dataset(half of batch)\n",
    "        bx0 = train_x[:tcu]  # 1/6\n",
    "        bx1 = test  # 3/6\n",
    "\n",
    "        # Out-of-distribution dataset(rest half of batch)\n",
    "        bx2 = train_x[tcu:2*tcu]  # 4/6\n",
    "        bx3 = train_x[2*tcu:3*tcu]  # 5/6\n",
    "        bx4 = train_x[3*tcu:]  # 6/6\n",
    "        by4 = train_y[3*tcu:]\n",
    "\n",
    "        assert(len(bx4) == len(by4))\n",
    "\n",
    "        # Make OOD samples by adding noise(see image_augmenting.py)\n",
    "        bx2 = add_distortion_noise(bx2)\n",
    "        bx3 = add_distortion_blur(bx3)\n",
    "        bx4 = rotate90_if_not_zero(bx4, by4)\n",
    "\n",
    "        # Stack altogether\n",
    "        bx = np.vstack((bx0, bx1, bx2, bx3, bx4))\n",
    "        by = np.zeros(len(bx))\n",
    "        by[:len(bx0) + len(bx1)] = 1\n",
    "        batch = [bx, by]\n",
    "\n",
    "        batches.append(batch)\n",
    "\n",
    "    aux_model.compile(optimizer='adam',\n",
    "                      loss={'risk_out': 'binary_crossentropy'})\n",
    "    aux_model.summary()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in batches:\n",
    "            bx, by = batch\n",
    "            aux_model.fit(bx,\n",
    "                          {'risk_out': by},\n",
    "                          batch_size=batch_size,\n",
    "                          verbose=0)\n",
    "\n",
    "    len_testset = mnist_test_x.shape[0]\n",
    "    test_result = aux_model.evaluate(x=mnist_test_x,\n",
    "                                     y=np.ones(shape=(len_testset, 1)))\n",
    "\n",
    "    print(\"metric names:\", aux_model.metrics_names)\n",
    "    print(test_result)\n",
    "\n",
    "    # Save model\n",
    "    keras.models.save_model(aux_model, \"./mnist_abnormal.hdf5\")\n",
    "    return aux_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "mnist = keras.datasets.mnist\n",
    "(mnist_train_x, mnist_train_y), (mnist_test_x, mnist_test_y)\\\n",
    "    = mnist.load_data()\n",
    "mnist_train_x = np.reshape(mnist_train_x, [-1, 28*28]) / 255.\n",
    "mnist_test_x = np.reshape(mnist_test_x, [-1, 28*28]) / 255.\n",
    "\n",
    "# Load Fashion MNIST\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(fmnist_train_x, fmnist_train_y), (fmnist_test_x, fmnist_test_y)\\\n",
    "    = fashion_mnist.load_data()\n",
    "fmnist_train_x = np.reshape(fmnist_train_x, [-1, 28*28]) / 255.\n",
    "fmnist_test_x = np.reshape(fmnist_test_x, [-1, 28*28]) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"h2\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"h2\" during training.\n",
      "WARNING:tensorflow:Output \"logits_out\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"logits_out\" during training.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "h1 (Dense)                      (None, 256)          200960      image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "h2 (Dense)                      (None, 256)          65792       h1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "bottleneck (Dense)              (None, 128)          32896       h2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "decode1 (Dense)                 (None, 256)          33024       bottleneck[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "h3 (Dense)                      (None, 256)          65792       h2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "decode2 (Dense)                 (None, 256)          65792       decode1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "logits_out (Dense)              (None, 10)           2570        h3[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "rec_output (Dense)              (None, 784)          201488      decode2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "merge3_ways (Merge3Ways)        (None, 512)          538112      image_input[0][0]                \n",
      "                                                                 h2[0][0]                         \n",
      "                                                                 logits_out[0][0]                 \n",
      "                                                                 rec_output[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "risk_1 (Dense)                  (None, 128)          65664       merge3_ways[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "risk_out (Dense)                (None, 1)            129         risk_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,272,219\n",
      "Trainable params: 603,905\n",
      "Non-trainable params: 668,314\n",
      "__________________________________________________________________________________________________\n",
      "10000/10000 [==============================] - 1s 98us/step\n",
      "metric names: ['loss', 'risk_out_loss']\n",
      "[0.0006618640095008004, 0.0006618640095008004]\n"
     ]
    }
   ],
   "source": [
    "base_model_path = './mnist_aux_base.hdf5'\n",
    "abnormal_model_path = './mnist_abnormal.hdf5'\n",
    "\n",
    "# Build base model if not exists\n",
    "if not os.path.exists(base_model_path):\n",
    "    base_model = train_aux_base_model()\n",
    "else:\n",
    "    base_model = keras.models.load_model(base_model_path)\n",
    "\n",
    "# Build abnormality module\n",
    "if not os.path.exists(abnormal_model_path):\n",
    "    abnormal_model = train_abnormal_model(base_model)\n",
    "else:\n",
    "    abnormal_model = train_abnormal_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[MNIST SUCCESS DETECTION]\n",
      "MNIST Error (%)| Prediction Prob (mean, std) | PProb Right (mean, std) | PProb Wrong (mean, std):\n",
      "1.8499970436096191 | 0.99024963 0.05453094 | 0.9936901 0.041456293 | 0.8077105 0.18870063\n",
      "Success base rate (%): 98.15 (9815/10000)\n",
      "KL[p||u]: Right/Wrong classification distinction\n",
      "AUPR (%): 99.92\n",
      "AUROC (%): 96.2\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 99.92\n",
      "AUROC (%): 96.19\n",
      "\n",
      "Error Detection\n",
      "Error base rate (%): 1.85 (185/10000)\n",
      "AUPR (%): 35.76\n",
      "AUROC (%): 96.2\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 37.01\n",
      "AUROC (%): 96.19\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3311cb3607f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m s_prob_right, s_prob_wrong, kl_right, kl_wrong =    exp.right_wrong_distinction(abnormal_model,\n\u001b[1;32m      2\u001b[0m                                 \u001b[0mmnist_test_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                 mnist_test_y,)\n\u001b[0m\u001b[1;32m      4\u001b[0m risk_in_f, risk_out_f =    exp.in_out_distinction(abnormal_model,\n\u001b[1;32m      5\u001b[0m                            \u001b[0mmnist_test_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "s_prob_right, s_prob_wrong, kl_right, kl_wrong =\\\n",
    "    exp.right_wrong_distinction(abnormal_model,\n",
    "                                mnist_test_x,\n",
    "                                mnist_test_y,)\n",
    "risk_in_f, risk_out_f =\\\n",
    "    exp.in_out_distinction(abnormal_model,\n",
    "                           mnist_test_x,\n",
    "                           fmnist_test_x,\n",
    "                           \"FashionMNIST\")\n",
    "risk_in_w, risk_out_w =\\\n",
    "    exp.in_out_distinction(abnormal_model,\n",
    "                           mnist_test_x,\n",
    "                           np.random.normal(size=(10000, 28*28)),\n",
    "                           \"WhiteNoise\")\n",
    "risk_in_u, risk_out_u =\\\n",
    "    exp.in_out_distinction(abnormal_model,\n",
    "                           mnist_test_x,\n",
    "                           np.random.uniform(size=(10000, 28*28)),\n",
    "                           \"UniformNoise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind right/wrong distinction result\n",
    "sp_rw = [s_prob_right, s_prob_wrong]\n",
    "kl_rw = [kl_right, kl_wrong]\n",
    "\n",
    "# Bind in/out of distribution detecting result of MNIST-FashionMNIST\n",
    "risk_iof = [risk_in_f, risk_out_f]\n",
    "\n",
    "# Bind in/out of distribution detecting result of MNIST-WhiteNoise\n",
    "risk_iow = [risk_in_w, risk_out_w]\n",
    "\n",
    "# Bind in/out of distribution detecting result of MNIST-UniformNoise\n",
    "risk_iou = [risk_in_u, risk_out_u]\n",
    "\n",
    "aux_result = { '[softmax] right/wrong': sp_rw, \n",
    "               '[softmax] in/out, MNIST/FashionMNIST': sp_iof, \n",
    "               '[softmax] in/out, MNIST/WhiteNoise': sp_iow,\n",
    "               '[softmax] in/out, MNIST/UniformNoise': sp_iou,\n",
    "               '[KLD] right/wrong': kl_rw, \n",
    "               '[KLD] in/out, MNIST/FashionMNIST': kl_iof, \n",
    "               '[KLD] in/out, MNIST/WhiteNoise': kl_iow, \n",
    "               '[KLD] in/out, MNIST/UniformNoise': kl_iou}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
